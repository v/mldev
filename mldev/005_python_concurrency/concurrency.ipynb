{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Python threading and concurrency practice\"\n",
    "format: \n",
    "    gfm:\n",
    "        echo: true\n",
    "jupyter: python3\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this post, I'm learning the basics of python's threading and concurrency libraries (like asyncio).\n",
    "\n",
    "This module is not strictly related to ML\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Threading library\n",
    "\n",
    "Let's understand the basics of how the Python threading library works.\n",
    "\n",
    "Consider the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with work\n",
      "Total time 1.0 secs\n"
     ]
    }
   ],
   "source": [
    "#| echo: true\n",
    "\n",
    "import time\n",
    "\n",
    "start = time.perf_counter()\n",
    "\n",
    "def worker():\n",
    "    time.sleep(1)\n",
    "    print(f'done with work')\n",
    "\n",
    "worker()\n",
    "\n",
    "end = time.perf_counter()\n",
    "print(f'Total time {round(end - start, 2)} secs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this code, our `worker` function is a simple synchronous function that takes 1s to finish.\n",
    "\n",
    "And the entire execution of the program is also synchronous. So the entire program finishes in 1s.\n",
    "\n",
    "If we were to call `worker` three times, we'd expect the program to take 3 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with work\n",
      "done with work\n",
      "done with work\n",
      "Total time 3.01 secs\n"
     ]
    }
   ],
   "source": [
    "#| echo: true\n",
    "\n",
    "import time\n",
    "\n",
    "start = time.perf_counter()\n",
    "\n",
    "def worker():\n",
    "    time.sleep(1)\n",
    "    print(f'done with work')\n",
    "\n",
    "worker()\n",
    "worker()\n",
    "worker()\n",
    "\n",
    "end = time.perf_counter()\n",
    "print(f'Total time {round(end - start, 2)} secs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, we can do better than this. Each piece of work takes 1 second, but we are waiting for one to finish before starting the other one.\n",
    "\n",
    "Let's see how we can use the threading library to resolve this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with workdone with work\n",
      "\n",
      "done with work\n",
      "Total time 1.01 secs\n"
     ]
    }
   ],
   "source": [
    "#| echo: true\n",
    "\n",
    "import threading\n",
    "import time\n",
    "\n",
    "start = time.perf_counter()\n",
    "\n",
    "def worker():\n",
    "    time.sleep(1)\n",
    "    print(f'done with work')\n",
    "\n",
    "# create three threads\n",
    "t1 = threading.Thread(target=worker)\n",
    "t2 = threading.Thread(target=worker)\n",
    "t3 = threading.Thread(target=worker)\n",
    "\n",
    "# when the threads are started, they execute independently\n",
    "# without waiting for each other\n",
    "t1.start()\n",
    "t2.start()\n",
    "t3.start()\n",
    "\n",
    "# wait for the threads to finish before moving on.\n",
    "t1.join()\n",
    "t2.join()\n",
    "t3.join()\n",
    "\n",
    "end = time.perf_counter()\n",
    "print(f'Total time {round(end - start, 2)} secs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This did make the entire execution take 1 second like we expect.\n",
    "\n",
    "Aside:\n",
    "\n",
    "Interestingly, the output of the program mixes up outputs from different threads, which is an indicator that `print` to stdout this context is not thread-safe.\n",
    "Also interestingly, this mixing up of output happens in a Jupyter notebook environment but not if you were to run this as a standalone shell program.\n",
    "\n",
    "The reason for this is explained in [this stackoverflow post](https://stackoverflow.com/questions/42867866/what-makes-python3s-print-function-thread-safe).\n",
    "\n",
    "> When interactive, stdout and stderr streams are line-buffered. Otherwise, they are block-buffered like regular text files. You can override this value with the -u command-line option.\n",
    "\n",
    "> So its really the combination of interactive mode and sys.stderr that is responsible for the behaviour of the print function [...]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ThreadPoolExecutor\n",
    "\n",
    "So far, we've been executing threads that print stuff.\n",
    "\n",
    "Let's see how we can return values from our threads to our main program. This is [pretty annoying to do with the raw `threading` module](https://stackoverflow.com/questions/6893968/how-to-get-the-return-value-from-a-thread-in-python), so we'll use a new API in Python 3.2 from the `concurrent.futures` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with work for 1\n",
      "done with work for 4\n",
      "done with work for 4\n",
      "Total time 4.01 secs\n"
     ]
    }
   ],
   "source": [
    "#| echo: true\n",
    "\n",
    "import random\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "random.seed(0)\n",
    "\n",
    "start = time.perf_counter()\n",
    "\n",
    "# our worker function now returns a value\n",
    "def worker(duration: float):\n",
    "    time.sleep(duration)\n",
    "    return(f'done with work for {duration}')\n",
    "\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    futures = []\n",
    "    for _ in range(3):\n",
    "        duration = random.choice(range(1, 5))\n",
    "        futures.append(executor.submit(worker, duration))\n",
    "\n",
    "    for f in as_completed(futures):\n",
    "        print(f.result())\n",
    "\n",
    "end = time.perf_counter()\n",
    "print(f'Total time {round(end - start, 2)} secs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is pretty cool. If our program has work that involves a lot of waiting (like making a network request), we can do distribute such work across multiple threads, and get their outputs in our main program.\n",
    "\n",
    "`ThreadPoolExecutor.submit` returns a `Future` and when we call `.result()` on it, we block until the future is resolved. A `Future` is pretty similar to a `Promise` in Javascript if you've come across it before.\n",
    "\n",
    "It is very common that you want to run the same piece of code across many threads. There is an even nicer syntax for this - `ThreadPoolExecutor.map`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with work for 4\n",
      "done with work for 4\n",
      "done with work for 1\n",
      "Total time 4.01 secs\n"
     ]
    }
   ],
   "source": [
    "#| echo: true\n",
    "\n",
    "import random\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "random.seed(0)\n",
    "\n",
    "start = time.perf_counter()\n",
    "\n",
    "def worker(duration: float):\n",
    "    time.sleep(duration)\n",
    "    return(f'done with work for {duration}')\n",
    "\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    data = [random.choice([1, 2, 3, 4]) for _ in range(3)]\n",
    "    results = executor.map(worker, data)\n",
    "    for r in results:\n",
    "        print(r)\n",
    "\n",
    "end = time.perf_counter()\n",
    "print(f'Total time {round(end - start, 2)} secs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output is slightly different because `ThreadPoolExecutor.map` returns results in the order that they were passed in.\n",
    "\n",
    "The same API can also be used to distribute work across multiple processes rather than multiple threads in the same process, which has the advantage of sidestepping the Python global interpreter lock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process SpawnProcess-10:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.10/3.10.8/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.10/3.10.8/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Cellar/python@3.10/3.10.8/Frameworks/Python.framework/Versions/3.10/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/homebrew/Cellar/python@3.10/3.10.8/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'worker' on <module '__main__' (built-in)>\n",
      "Process SpawnProcess-11:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.10/3.10.8/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.10/3.10.8/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Cellar/python@3.10/3.10.8/Frameworks/Python.framework/Versions/3.10/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/homebrew/Cellar/python@3.10/3.10.8/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'worker' on <module '__main__' (built-in)>\n"
     ]
    },
    {
     "ename": "BrokenProcessPool",
     "evalue": "A process in the process pool was terminated abruptly while the future was running or pending.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBrokenProcessPool\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [13], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m     data \u001b[39m=\u001b[39m [random\u001b[39m.\u001b[39mchoice([\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m4\u001b[39m]) \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m3\u001b[39m)]\n\u001b[1;32m     19\u001b[0m     results \u001b[39m=\u001b[39m exe\u001b[39m.\u001b[39mmap(worker, data)\n\u001b[0;32m---> 20\u001b[0m     \u001b[39mfor\u001b[39;00m r \u001b[39min\u001b[39;00m results:\n\u001b[1;32m     21\u001b[0m         \u001b[39mprint\u001b[39m(r)\n\u001b[1;32m     23\u001b[0m end \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mperf_counter()\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.8/Frameworks/Python.framework/Versions/3.10/lib/python3.10/concurrent/futures/process.py:570\u001b[0m, in \u001b[0;36m_chain_from_iterable_of_lists\u001b[0;34m(iterable)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_chain_from_iterable_of_lists\u001b[39m(iterable):\n\u001b[1;32m    565\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    566\u001b[0m \u001b[39m    Specialized implementation of itertools.chain.from_iterable.\u001b[39;00m\n\u001b[1;32m    567\u001b[0m \u001b[39m    Each item in *iterable* should be a list.  This function is\u001b[39;00m\n\u001b[1;32m    568\u001b[0m \u001b[39m    careful not to keep references to yielded objects.\u001b[39;00m\n\u001b[1;32m    569\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 570\u001b[0m     \u001b[39mfor\u001b[39;00m element \u001b[39min\u001b[39;00m iterable:\n\u001b[1;32m    571\u001b[0m         element\u001b[39m.\u001b[39mreverse()\n\u001b[1;32m    572\u001b[0m         \u001b[39mwhile\u001b[39;00m element:\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.8/Frameworks/Python.framework/Versions/3.10/lib/python3.10/concurrent/futures/_base.py:621\u001b[0m, in \u001b[0;36mExecutor.map.<locals>.result_iterator\u001b[0;34m()\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[39mwhile\u001b[39;00m fs:\n\u001b[1;32m    619\u001b[0m     \u001b[39m# Careful not to keep a reference to the popped future\u001b[39;00m\n\u001b[1;32m    620\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 621\u001b[0m         \u001b[39myield\u001b[39;00m _result_or_cancel(fs\u001b[39m.\u001b[39;49mpop())\n\u001b[1;32m    622\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    623\u001b[0m         \u001b[39myield\u001b[39;00m _result_or_cancel(fs\u001b[39m.\u001b[39mpop(), end_time \u001b[39m-\u001b[39m time\u001b[39m.\u001b[39mmonotonic())\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.8/Frameworks/Python.framework/Versions/3.10/lib/python3.10/concurrent/futures/_base.py:319\u001b[0m, in \u001b[0;36m_result_or_cancel\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    318\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 319\u001b[0m         \u001b[39mreturn\u001b[39;00m fut\u001b[39m.\u001b[39;49mresult(timeout)\n\u001b[1;32m    320\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    321\u001b[0m         fut\u001b[39m.\u001b[39mcancel()\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.8/Frameworks/Python.framework/Versions/3.10/lib/python3.10/concurrent/futures/_base.py:458\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    457\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[0;32m--> 458\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__get_result()\n\u001b[1;32m    459\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    460\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m()\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.8/Frameworks/Python.framework/Versions/3.10/lib/python3.10/concurrent/futures/_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[1;32m    402\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 403\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[1;32m    404\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m         \u001b[39m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    406\u001b[0m         \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[0;31mBrokenProcessPool\u001b[0m: A process in the process pool was terminated abruptly while the future was running or pending."
     ]
    }
   ],
   "source": [
    "#| output: false\n",
    "import random\n",
    "import time\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "\n",
    "def worker(duration: float):\n",
    "    time.sleep(duration)\n",
    "    return f\"done with work for {duration}\"\n",
    "\n",
    "\n",
    "# we moved all our code under this if statement\n",
    "# to enable this code to run across multiple processes\n",
    "if __name__ == \"__main__\":\n",
    "    random.seed(0)\n",
    "\n",
    "    start = time.perf_counter()\n",
    "\n",
    "    with ProcessPoolExecutor() as exe:\n",
    "        data = [random.choice([1, 2, 3, 4]) for _ in range(3)]\n",
    "        results = exe.map(worker, data)\n",
    "        for r in results:\n",
    "            print(r)\n",
    "\n",
    "    end = time.perf_counter()\n",
    "    print(f\"Total time {round(end - start, 2)} secs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code doesn't run in a Juptyer notebook, but it does run nicely as a standalone shell program.\n",
    "\n",
    "We added a conditional `if __name__ == '__main__'` because the `ProcessPoolExecutor` should be triggering a new execution only when the parent program is running, not when each of the `worker` programs are running."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## asyncio \n",
    "\n",
    "There is an alternate way of writing concurrent code in Python, which is using the `asyncio` module and `async/await` syntax.\n",
    "\n",
    "This syntax was introduced in Python 3.4.\n",
    "\n",
    "There is a fantastic comparision of `asyncio` vs `threading` / `concurrent.futures` in [this blog post](http://masnun.rocks/2016/10/06/async-python-the-different-forms-of-concurrency/).\n",
    "\n",
    "Let's see how we'd write similar programs using asyncio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we mark functions `async` and call them, they don't return their result anymore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "foo=<coroutine object foo at 0x109b09a80>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/v4/zcl4mdss439gswj_l5kb2mr00000gn/T/ipykernel_12088/2004336360.py:6: RuntimeWarning: coroutine 'foo' was never awaited\n",
      "  print(f\"foo={foo()}\")\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "source": [
    "#| echo: true\n",
    "import asyncio\n",
    "\n",
    "async def foo():\n",
    "    return 'hello'\n",
    "\n",
    "print(f\"foo={foo()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that `foo()` doesn't return `'hello'` like we expect\n",
    "\n",
    "Instead, it returns a coroutine object. We can have to execute this coroutine object in order to get the result back.\n",
    "\n",
    "We can do this by using the `await` keyword."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "foo=hello\n"
     ]
    }
   ],
   "source": [
    "#| echo: true\n",
    "import asyncio\n",
    "\n",
    "async def foo():\n",
    "    return 'hello'\n",
    "\n",
    "print(f\"foo={await foo()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This works nicely, but only because we're running in a Jupyter notebook.\n",
    "\n",
    "If we ran this in a standalone Python shell, we'd need slightly different syntax.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Cellar/python@3.10/3.10.8/Frameworks/Python.framework/Versions/3.10/lib/python3.10/genericpath.py:77: RuntimeWarning: coroutine 'main' was never awaited\n",
      "  m = tuple(map(os.fspath, m))\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "asyncio.run() cannot be called from a running event loop",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [31], line 15\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[39mawait\u001b[39;00m foo()\n\u001b[1;32m     11\u001b[0m \u001b[39m# This syntax doesn't work in a Jupyter notebook cell because \u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[39m# Jupyter is already running an asyncio event loop.\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[39m# but it works in a standalone python shell\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m asyncio\u001b[39m.\u001b[39;49mrun(main())\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.8/Frameworks/Python.framework/Versions/3.10/lib/python3.10/asyncio/runners.py:33\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(main, debug)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[39m\"\"\"Execute the coroutine and return the result.\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \n\u001b[1;32m     11\u001b[0m \u001b[39mThis function runs the passed coroutine, taking care of\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[39m    asyncio.run(main())\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[39mif\u001b[39;00m events\u001b[39m.\u001b[39m_get_running_loop() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 33\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m     34\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39masyncio.run() cannot be called from a running event loop\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     36\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m coroutines\u001b[39m.\u001b[39miscoroutine(main):\n\u001b[1;32m     37\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39ma coroutine was expected, got \u001b[39m\u001b[39m{!r}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(main))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: asyncio.run() cannot be called from a running event loop"
     ]
    }
   ],
   "source": [
    "#| output: false\n",
    "\n",
    "import asyncio\n",
    "\n",
    "async def foo():\n",
    "    return 'hello'\n",
    "\n",
    "async def main():\n",
    "    await foo()\n",
    "\n",
    "# This syntax doesn't work in a Jupyter notebook cell because \n",
    "# Jupyter is already running an asyncio event loop.\n",
    "#\n",
    "# but it works in a standalone python shell\n",
    "asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we see what a coroutine is, let's write some code that waits for a long time to see how we'd write such code using `asyncio`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time 3.01 secs\n"
     ]
    }
   ],
   "source": [
    "#| output: false\n",
    "\n",
    "import asyncio\n",
    "import time\n",
    "\n",
    "\n",
    "def foo():\n",
    "    time.sleep(1)\n",
    "    return 'hello'\n",
    "\n",
    "async def main():\n",
    "    start = time.perf_counter()\n",
    "    \n",
    "    # these are plain old synchronous function calls\n",
    "    foo()\n",
    "    foo()\n",
    "    foo()\n",
    "\n",
    "    end = time.perf_counter()\n",
    "\n",
    "    print(f'Total time {round(end - start, 2)} secs')\n",
    "\n",
    "\n",
    "await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above isn't anything fancy. `main()` makes three synchronous function calls to `foo()` and takes a total of 3 seconds to run.\n",
    "\n",
    "To make the waiting happen concurrently, we'll switch from using `time.sleep` to `asyncio.sleep`, and add some `async` / `await` keywords.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done sleeping 1 sec\n",
      "done sleeping 1 sec\n",
      "done sleeping 1 sec\n",
      "Total time 3.0 secs\n"
     ]
    }
   ],
   "source": [
    "#| output: false\n",
    "\n",
    "import asyncio\n",
    "import time\n",
    "\n",
    "\n",
    "async def foo():\n",
    "    # wait for the sleep to finish before executing the next commmand\n",
    "    await asyncio.sleep(1)\n",
    "    return f'done sleeping 1 sec'\n",
    "\n",
    "async def main():\n",
    "    start = time.perf_counter()\n",
    "    \n",
    "    # these will still behave like plain old synchronous function calls\n",
    "    # we will finish one before moving on to the next one\n",
    "    print(await foo())\n",
    "    print(await foo())\n",
    "    print(await foo())\n",
    "\n",
    "    end = time.perf_counter()\n",
    "\n",
    "    print(f'Total time {round(end - start, 2)} secs')\n",
    "\n",
    "\n",
    "await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We added some async looking code, but our overall runtime hasn't changed yet.\n",
    "\n",
    "This is because we are waiting for each `foo()` coroutine to finish before starting the next one.\n",
    "\n",
    "Instead, we want to start all of them, and then wait for all of them to finish.\n",
    "\n",
    "This is where the concept of a `task` comes in handy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done sleeping 1 sec\n",
      "done sleeping 1 sec\n",
      "done sleeping 1 sec\n",
      "Total time 1.0 secs\n"
     ]
    }
   ],
   "source": [
    "#| output: false\n",
    "\n",
    "import asyncio\n",
    "import time\n",
    "\n",
    "\n",
    "async def foo():\n",
    "    # wait for the sleep to finish before executing the next commmand\n",
    "    await asyncio.sleep(1)\n",
    "    return f'done sleeping 1 sec'\n",
    "\n",
    "async def main():\n",
    "    start = time.perf_counter()\n",
    "    \n",
    "    # we run each coroutine in a task\n",
    "    # this means that anytime one of them pauses, execution\n",
    "    # proceeds on another one\n",
    "\n",
    "    t1 = asyncio.create_task(foo())\n",
    "    t2 = asyncio.create_task(foo())\n",
    "    t3 = asyncio.create_task(foo())\n",
    "\n",
    "    print(await t1)\n",
    "    print(await t2)\n",
    "    print(await t3)\n",
    "\n",
    "    end = time.perf_counter()\n",
    "\n",
    "    print(f'Total time {round(end - start, 2)} secs')\n",
    "\n",
    "\n",
    "await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice, this lets us run long-running code and get return values back.\n",
    "\n",
    "Looking at both `concurrent.futures` and `asyncio`, **I'd prefer using `asyncio` when we're doing different IO operations in sequence**.\n",
    "\n",
    "For example, if you're writing a function that hits your database, then a third party API, then a cloud-storage service, you could write this code by chaining together three `await` calls.\n",
    "Writing such code using the `threading` library wouldn't be so nice, because creating a new thread for each different piece of work would require more code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### asyncio Queues \n",
    "\n",
    "`asyncio.Queue` is a handy module for sharing data between different coroutines\n",
    "\n",
    "Let's recreate the same example using a queue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "worker-3 slept for 2 secs\n",
      "worker-2 slept for 3 secs\n",
      "worker-1 slept for 4 secs\n",
      "worker-3 slept for 4 secs\n",
      "worker-2 slept for 4 secs\n",
      "worker-1 slept for 3 secs\n",
      "worker-3 slept for 1 secs\n",
      "worker-2 slept for 1 secs\n",
      "worker-1 slept for 1 secs\n",
      "worker-3 slept for 4 secs\n",
      "Total time 11.0 secs\n"
     ]
    }
   ],
   "source": [
    "#| output: false\n",
    "\n",
    "import asyncio\n",
    "import time\n",
    "\n",
    "\n",
    "async def foo(name, q):\n",
    "    while True:\n",
    "        duration = await q.get()\n",
    "\n",
    "        await asyncio.sleep(duration)\n",
    "        q.task_done()\n",
    "\n",
    "        print(f'{name} slept for {duration} secs')\n",
    "\n",
    "async def main():\n",
    "    q = asyncio.Queue()\n",
    "    start = time.perf_counter()\n",
    "    \n",
    "    # create three worker tasks\n",
    "    t1 = asyncio.create_task(foo('worker-1', q))\n",
    "    t2 = asyncio.create_task(foo('worker-2', q))\n",
    "    t3 = asyncio.create_task(foo('worker-3', q))\n",
    "\n",
    "\n",
    "    # add 10 items to the queue\n",
    "    for _ in range(10):\n",
    "        duration = random.choice(range(1, 5))\n",
    "        q.put_nowait(duration)\n",
    "\n",
    "    # wait for all items from the queue to be fully processed\n",
    "    await q.join()\n",
    "\n",
    "    # stop executing the workers\n",
    "    t1.cancel()\n",
    "    t2.cancel()\n",
    "    t3.cancel()\n",
    "    \n",
    "    asyncio.gather(t1, t2, t3, return_exceptions=True)\n",
    "    end = time.perf_counter()\n",
    "    print(f'Total time {round(end - start, 2)} secs')\n",
    "\n",
    "\n",
    "await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7feba0c39194aeb14b5e7bd5560b8c45dc2d3c126975e5595ee228f6b74cec04"
  },
  "kernelspec": {
   "display_name": "Python 3.10.7 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
